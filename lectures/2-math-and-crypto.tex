\documentclass[../lecture-notes.tex]{subfiles}

\begin{document}

\subsection{Basics of Security Analysis}

In many cases, technical papers include the analysis on the key question: ``How secure is this cryptographic algorithm?'' or rather ``Why this cryptographic algorithm is secure?''. In this section, we will shortly describe the notation and typical construction for justifying the security of cryptographic algorithms.

Typically, the cryptographic security is defined in a form of a game between the adversary (who we call $\mathcal{A}$) and the challenger (who we call $\mathcal{C}h$). The adversary is trying to break the security of the cryptographic algorithm using arbitrary (but still efficient) protocol, while the challenger is following a simple, fixed protocol. The game is played in a form of a challenge, where the adversary is given some information and is asked to perform some task. The security of the cryptographic algorithm is defined based on the probability of the adversary to win the game.

\subsubsection{Cipher Semantic Security}
Let us get into specifics. Suppose that we want to specify that the encryption scheme is secure. Recall that cipher $\mathcal{E} = (E,D)$ over the space $(\mathcal{K}, \mathcal{M}, \mathcal{C})$ (here, $\mathcal{K}$ is the space containing all possible keys, $\mathcal{M}$ --- all possible messages and $\mathcal{C}$ --- all possible ciphers) consists of two efficiently computable methods:
\begin{itemize}
    \item $E: \mathcal{K} \times \mathcal{M} \to \mathcal{C}$ --- encryption method, that based on the provided message $m \in \mathcal{M}$ and key $k \in \mathcal{K}$ outputs the cipher $c = E(k,m) \in \mathcal{C}$.
    \item $D: \mathcal{K} \times \mathcal{C} \to \mathcal{M}$ --- decryption method, that based on the provided cipher $c \in \mathcal{C}$ and key $k \in \mathcal{K}$ outputs the message $m = D(k,c) \in \mathcal{M}$.
\end{itemize}

Of course, we require the \textbf{correctness}:
\begin{equation}
    (\forall k \in \mathcal{K}) \, (\forall m \in \mathcal{M}): \{D(k,E(k,m)) = m\}
\end{equation}

Now let us play the following game between adversary $\mathcal{A}$ and challenger $\mathcal{C}h$:
\begin{enumerate}
    \item $\mathcal{A}$ picks any two messages $m_0,m_1 \in \mathcal{M}$ on his choice.
    \item $\mathcal{C}h$ picks a random key $k \xleftarrow{R} \mathcal{K}$ and random bit $b \xleftarrow{R} \{0,1\}$ and sends the cipher $c = E(k,m_b)$ to $\mathcal{A}$.
    \item $\mathcal{A}$ is trying to guess the bit $b$ by using the cipher $c$.
    \item $\mathcal{A}$ outputs the guess $\hat{b}$.
\end{enumerate}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \node[inner sep=0pt, align=center] (challenger) {\includegraphics[width=0.75cm]{lectures/images/lecture_2/challenger.png}\\Challenger $\mathcal{C}h$};
        \node[inner sep=0pt, align=center, right=5cm of challenger] (adversary) {\includegraphics[width=0.75cm]{lectures/images/lecture_2/demon.png}\\Adversary $\mathcal{A}$};

        \draw [dashed,line width=0.3mm] ([yshift=-0.5cm]challenger.south) -- ([yshift=-9cm]challenger.south);
        \draw [dashed,line width=0.3mm] ([yshift=-0.5cm]adversary.south) -- ([yshift=-9cm]adversary.south);

        \draw[-{Stealth[length=3mm]},line width=0.4mm] ([yshift=-1.5cm]adversary.south) coordinate (l2)--(l2-|challenger) node[midway, above=2mm, fill=white]{Send $m_0, m_1 \in \mathcal{M}, |m_0| = |m_1|$};

        \node[align=center,fill=white!5,thick,below=2.5cm of challenger](challenger-actions){
        \noindent\rule{3.5cm}{0.8pt}\\
        $b \xleftarrow{R} \{0,1\}$ \\
        $k \xleftarrow{R} \mathcal{K}$ \\
        $c \gets E(k,m_b)$ \\
        \noindent\rule{3.5cm}{0.8pt}};

        \draw[-{Stealth[length=3mm]},line width=0.4mm] ([yshift=-6cm]challenger.south) coordinate (l2)--(l2-|adversary) node[midway, above=2mm, fill=white]{Send cipher $c$};

        \node[align=center,fill=white!5,thick,below=7cm of adversary](adversary-guess){
        \noindent\rule{3.5cm}{0.8pt}\\
        Guess bit $\hat{b} \in \{0,1\}$\\
        \noindent\rule{3.5cm}{0.8pt}};
    \end{tikzpicture}

    \caption{The game between the adversary $\mathcal{A}$ and the challenger $\mathcal{C}h$ for defining the semantic security.}
\end{figure}

Now, what should happen if our encryption scheme is secure? The adversary should not be able to guess the bit $b$ with a probability significantly higher than $1/2$ (a random guess). Formally, define the 
\textbf{advantage} of the adversary $\mathcal{A}$ as:
\begin{equation}
    \text{SSAdv}[\mathcal{E}, \mathcal{A}] := \left| \Pr[\hat{b} = b] - \frac{1}{2} \right|
\end{equation}

We say that the encryption scheme is \textbf{semantically secure}\footnote{This version of definition is called a \textbf{bit-guessing} version.} if for any efficient adversary $\mathcal{A}$ the advantage $\text{SSAdv}[\mathcal{A}]$ is negligible. In other words, the adversary cannot guess the bit $b$ with a probability significantly higher than $1/2$.

Now, what negligible means? Let us give the formal definition!

\begin{definition}
    A function $f: \mathbb{N} \to \mathbb{R}$ is called \textbf{negligible} if for all $c \in \mathbb{R}_{>0}$ there exists $n_c \in \mathbb{N}$ such that for any $n \geq n_c$ we have $|f(n)| < 1/n^c$.
\end{definition}

The alternative definition, which is problably easier to interpret, is the following.

\begin{theorem}
    A function $f: \mathbb{N} \to \mathbb{R}$ is \textbf{negligible} if and only if for any $c \in \mathbb{R}_{>0}$, we have
    \begin{equation}
        \lim_{n \to \infty} f(n)n^c = 0
    \end{equation}
\end{theorem}

\begin{example}
    The function $f(n) = 2^{-n}$ is negligible since for any $c \in \mathbb{R}_{>0}$ we have
    \begin{equation}
        \lim_{n \to \infty} 2^{-n}n^c = 0
    \end{equation}

    The function $g(n) = \frac{1}{n!}$ is also negligible for similar reasons.
\end{example}

\begin{example}
    The function $h(n) = \frac{1}{n}$ is not negligible since for $c = 1$ we have
    \begin{equation}
        \lim_{n \to \infty} \frac{1}{n} \times n = 1 \neq 0
    \end{equation}
\end{example}

Well, that is weird. For some reason we are considering a function the depends on some natural number $n$, but what is this number?

Typically, when defining the security of the cryptographic algorithm, we are considering the security parameter $\lambda$ (e.g., the length of the key). The function is negligible if the probability of the adversary to break the security of the cryptographic algorithm is decreasing with the increasing of the security parameter $\lambda$. Moreover, we require that the probability of the adversary to break the security of the cryptographic algorithm is decreasing faster than any polynomial function of the security parameter $\lambda$.

So all in all, we can define the semantic security as follows.

\begin{definition}
    The encryption scheme $\mathcal{E}$ with a security paramter $\lambda \in \mathbb{N}$ is \textbf{semantically secure} if for any efficient adversary $\mathcal{A}$ we have:
    \begin{equation}
        \left|\text{Pr}\begin{bmatrix}[c|c]
            & m_0, m_1 \gets \mathcal{A}, \; k \xleftarrow{R} \mathcal{K}, \; b \xleftarrow{R} \{0,1\} \\
            b = \hat{b} & c \gets E(k,m_b) \\
            &\hat{b} \gets \mathcal{A}(c)
        \end{bmatrix} - \frac{1}{2}\right| < \text{negl}(\lambda)
    \end{equation}
\end{definition}

Do not be afraid of such complex notation, it is quite simple. Notation $\text{Pr}[A \mid B]$ means ``the probability of $A$, given that $B$ occurred''. So our inner probability is read as ``the probability that the guessed bit $\hat{b}$ equals $b$ given the setup on the right''. Then, on the right we define the setup: first we generate two messages $m_0,m_1 \in \mathcal{M}$, then we choose a random bit $b$ and a key $k$, cipher the message $m_b$, send it to the adversary and the adversary, based on provided cipher, gives $\hat{b}$ as an output. We then claim that the probability of the adversary to guess the bit $b$ is close to $1/2$.

Let us see some more examples of how to define the security of certain crypographic objects.

\subsubsection{Message recovery attacks}

Essentially, message recovery attacks are types of attacks that, from given ciphertext, recover the message with significantly better probability than random guessing, which is obvious $1/|\mathcal{M}|$.
Of course, any reasonable notion of security should rule out such an attack, and indeed, semantic security does.

Although this might seem intuitively obvious, we provide a formal proof to clarify the reasoning. 
One of the reasons for doing this is to thoroughly demonstrate the concept of a \emph{security reduction}, which is the primary method used to assess the security of systems.

Let us play the following attack game message recovery between adversary $\mathcal{A}$ and challenger $\mathcal{C}h$.
For a given cipher $\mathcal{E} = (E, D)$, defined over $\mathcal{K}, \mathcal{M}, \mathcal{C}$, and for a given adversary $\mathcal{A}$, the attack game proceeds as follows: 

\begin{itemize}
    \item The challenger computes $m \xleftarrow{R} \mathcal{M}$, $k \xleftarrow{R} \mathcal{K}$, $c \xleftarrow{R} E(k, m)$ and sends c to the adversary.
    \item the adversary output a message $\hat{m} \in \mathcal{M}$.
\end{itemize}

We say that $\mathcal{A}$ wins the game in this case, and we define $\mathcal{A}$'s message recovery advantage with respect to $\mathcal{E}$ as:

\begin{equation*}
    \text{MRadv}[\mathcal{A}, \mathcal{E}] := \Bigg|\text{Pr}[\hat{m} = m] - \frac{1}{|\mathcal{M}|}\Bigg|.
\end{equation*}

\begin{definition} [Security against message recovery]
    A cipher $\mathcal{E}$ is secure against message recovery if for all efficient adversaries $\mathcal{A}$, the value MRadv[$\mathcal{A}$, $\mathcal{E}$] is negligible.
\end{definition}

\begin{theorem}
    Let $\mathcal{E} = (E, D)$ be a cipher defined over $(\mathcal{K}, \mathcal{M}, \mathcal{C})$. If $\mathcal{E}$ is semantically secure then $\mathcal{E}$ is secure against message recovery.
\end{theorem}

$\blacktriangleright$ 
Let us prove by assuming the opposite statement. 
In other words if $\mathcal{E}$ is not secure against message recovery, then $\mathcal{E}$ is not semantically secure.

Assume that $\mathcal{E}$ is not secure against message recovery. 
We have efficient adversary $\mathcal{A}$ who have significant advantage in 
message recovery game and efficient adversary $\mathcal{B}$ who is trying to 
compromise $\mathcal{E}$.  
The proof idea is to use efficient adversary $\mathcal{A}$ as a "black box" (or oracle machine). % that wins message recovery game.
We construct $\mathcal{B}$ as follows:
\begin{enumerate}
    \item Adversary $\mathcal{B}$ generates $m_0, m_1 \in \mathcal{M}$ and sends to semantic security challenger.
    \item Semantic security challenger returns ciphertext $c$ which goes to adversary $\mathcal{A}$.
    \item $\mathcal{A}$ returns $\hat{m}$. If $\hat{m} = m_0$, then $b = 0$, otherwise $b = 1$.
    \item Sends $b$ to semantic security challenger. 
\end{enumerate}

Intuitively, this implies that $\text{SSadv}[\mathcal{B}, \mathcal{E}]$ is exactly equal 
to $\text{MRadv}[\mathcal{A}, \mathcal{E}]$. $\blacktriangleleft$

% This essentially means that if an adversary is capable of successfully winning the 
This means that if an adversary is capable of successfully winning the 
message recovery game, then they can also effectively win the semantic security game.
In essence, security against message recovery is a stronger property than
semantic security. 

% The reader could have a reasonable question. Why did we describe this proof at all? 
% One of our motivations for doing this is to illustrate in detail the notion of a security reduction, which is the main technique used to reason about the security of systems.

To be more formal, we introduce how security reduction works in general. 
\begin{definition} [Security Reduction]
    \hfill
    \begin{enumerate}
        \item Let $\mathcal{A}$ be an efficient adversary, who is trying to compromise the cryptosystem $\mathcal{E}$.
        \item Construct efficient algorithm $\mathcal{A}'$, which we will call the reduction that will solve computational hard problem $\mathcal{X}$ while using oracle access to A. 
        For any input $x$ of the problem $\mathcal{X}$ algorithm $\mathcal{A}'$ generates the input of the cryptosystem $\mathcal{E}$ for $\mathcal{A}$.
        Once it wins the corresponding experiment, $\mathcal{A}'$ solves $\mathcal{X}$ for input $x$ with probability $\leq 1/n^c, c \in \mathbb{N}$.
        \item Thus, algorithm $\mathcal{A}'$ solve $\mathcal{X}$ with the negligible probability $\varepsilon(n)/n^c$ if $\varepsilon(n)$ is negligible.
        \item Since the problem $\mathcal{X}$ is computationally hard, we get a contradiction. It follows that no attacker $\mathcal{A}$ can effectively crack $\mathcal{E}$, i.e., this cryptosystem is computationally strong.
    \end{enumerate}
\end{definition}

\subsubsection{Case study: RSA}

In this section we will demonstrate one of the oldest widely used for secure data transmission public-key cryptosystem RSA.
Our main goal is to describe cryptosystem, proof correctness and talk about security considerations. 

\begin{algorithm}[H]
    \caption{RSA key generation} \label{alg:rsa_key_generation}
    \Input{$e \in \mathbb{N}$, $l$ --- key length}
    \Output{$(n, d)$}

    $p \xleftarrow{R} \{ \text{Prime number of length } l/2 \}$ \\
    $q \xleftarrow{R} \{ \text{Prime number of length } l/2 \}$ \\
    $n \gets pq$ \\
    if (gcd$(e, \varphi(n))\neq 1$) goto step 1 \\
    $d \gets$ ModularInverse$(e, \varphi(n))$ \\
    
    \textbf{return} $(n, d)$
\end{algorithm}

The RSA encryption and decryption process can be described as follows:

\textbf{Encryption:}
\begin{equation*}
    C = M^e \pmod{n}
\end{equation*}
where \( M \) is the plaintext message, \( e \) is the public exponent, and \( n \) is the modulus (part of the public key).

\textbf{Decryption:}
\begin{equation*}
    M = C^d \pmod{n}
\end{equation*}
where \( C \) is the ciphertext, \( d \) is the private exponent, and \( n \) is the modulus (part of the private key).


\begin{remark}
    In real world usually $e = 2^{16} + 1$.
\end{remark}

\subsubsection{Discrete Logarithm Assumption (DL)}

Now, let us define the fundamental assumption used in cryptography formally: the \textbf{Discrete Logarithm Assumption} (DL).

\begin{definition}
    Assume that $\mathbb{G}$ is a cyclic group of prime order $r$ generated by $g \in \mathbb{G}$. Define the following game:
    \begin{enumerate}
        \item Both challenger $\mathcal{C}h$ and adversary $\mathcal{A}$ take a description $\mathbb{G}$ as an input: order $r$ and generator $g \in \mathbb{G}$.
        \item $\mathcal{C}h$ computes $\alpha \xleftarrow{R} \mathbb{Z}_r, u \gets g^{\alpha}$ and sends $u \in \mathbb{G}$ to $\mathcal{A}$.
        \item The adversary $\mathcal{A}$ outputs $\hat{\alpha} \in \mathbb{Z}_r$.
    \end{enumerate}

    We define $\mathcal{A}$'s \textbf{advantage in solving the discrete logarithm problem in $\mathbb{G}$}, denoted as $\text{DL}\mathsf{adv}[\mathcal{A},\mathbb{G}]$, as the probability that $\hat{\alpha} = \alpha$.
\end{definition}

\begin{definition}
    The \textbf{Discrete Logarithm Assumption} holds in the group $\mathbb{G}$ if for any efficient adversary $\mathcal{A}$ the advantage $\text{DL}\mathsf{adv}[\mathcal{A},\mathbb{G}]$ is negligible.
\end{definition}

Informally, this assumption means that given $u$, it is very hard to find $\alpha$ such that $u = g^{\alpha}$. But now we can write down this formally!

\subsubsection{Computational Diffie-Hellman (CDH)}

Another fundamental problem in cryptography is the \textbf{Computational Diffie-Hellman} (CDH) problem. It states that given $g^{\alpha},g^{\beta}$ it is hard to find $g^{\alpha\beta}$. This property is frequently used in the construction of cryptographic protocols such as the Diffie-Hellman key exchange.

Let us define this problem formally.

\begin{definition}
    Let $\mathbb{G}$ be a cyclic group of prime order $r$ generated by $g \in \mathbb{G}$. Define the following game:
    \begin{enumerate}
        \item Both challenger $\mathcal{C}h$ and adversary $\mathcal{A}$ take a description $\mathbb{G}$ as an input: order $r$ and generator $g \in \mathbb{G}$.
        \item $\mathcal{C}h$ computes $\alpha, \beta \xleftarrow{R} \mathbb{Z}_r, u \gets g^{\alpha}, v \gets g^{\beta}, w \gets g^{\alpha\beta}$ and sends $u,v \in \mathbb{G}$ to $\mathcal{A}$.
        \item The adversary $\mathcal{A}$ outputs $\hat{w} \in \mathbb{G}$.
    \end{enumerate}

    We define $\mathcal{A}$'s \textbf{advantage in solving the computational Diffie-Hellman problem in $\mathbb{G}$}, denoted as $\text{CDH}\mathsf{adv}[\mathcal{A},\mathbb{G}]$, as the probability that $\hat{w} = w$.
\end{definition}

\begin{definition}
    The \textbf{Computational Diffie-Hellman Assumption} holds in the group $\mathbb{G}$ if for any efficient adversary $\mathcal{A}$ the advantage $\text{CDH}\mathsf{adv}[\mathcal{A},\mathbb{G}]$ is negligible.
\end{definition}

\subsubsection{Decisional Diffie-Hellman (DDH)}

Now, we loosen the requirements a bit. The \textbf{Decisional Diffie-Hellman} (DDH) problem states that given $g^{\alpha},g^{\beta},g^{\alpha\beta}$ it is ``hard'' to distinguish $g^{\alpha\beta}$ from a random element in $\mathbb{G}$. Formally, we define this problem as follows.

\begin{definition}
    Let $\mathbb{G}$ be a cyclic group of prime order $r$ generated by $g \in \mathbb{G}$. Define the following game:
    \begin{enumerate}
        \item Both challenger $\mathcal{C}h$ and adversary $\mathcal{A}$ take a description $\mathbb{G}$ as an input: order $r$ and generator $g \in \mathbb{G}$.
        \item $\mathcal{C}h$ computes $\alpha, \beta,\gamma \xleftarrow{R} \mathbb{Z}_r, u \gets g^{\alpha}, v \gets g^{\beta}, w_0 \gets g^{\alpha\beta}, w_1 \gets g^{\gamma}$. Then, $\mathcal{C}h$ flips a coin $b \xleftarrow{R} \{0,1\}$ and sends $u,v,w_b$ to $\mathcal{A}$.
        \item The adversary $\mathcal{A}$ outputs the predicted bit $\hat{b} \in \{0,1\}$.
    \end{enumerate}

    We define $\mathcal{A}$'s \textbf{advantage in solving the Decisional Diffie-Hellman problem in $\mathbb{G}$}, denoted as $\text{DDH}\mathsf{adv}[\mathcal{A},\mathbb{G}]$, as
    \begin{equation}
        \text{DDH}\mathsf{adv}[\mathcal{A},\mathbb{G}] := \left| \Pr[b = \hat{b}] - \frac{1}{2} \right|
    \end{equation}
\end{definition}

Now, let us break this assumption for some quite generic group! Consider the following example.

\begin{theorem}
    Suppose that $\mathbb{G}$ is a cyclic group of an even order. Then, the Decision
    Diffie-Hellman Assumption does not hold in $\mathbb{G}$. In fact, there is an efficient adversary $\mathcal{A}$ that can distinguish $g^{\alpha\beta}$ from a random element in $\mathbb{G}$ with an advantage $1/4$.
\end{theorem}

\textbf{Proof.} If $|\mathbb{G}|=2n$ for $n \in \mathbb{N}$, it means that we can split the group into two subgroups of order $n$, say, $\mathbb{G}_1$ and $\mathbb{G}_2$. The first subgroup consists of elements in a form $g^{2k}$, while the second subgroup consists of elements in a form $g^{2k+1}$.

Now, if we could efficiently determine, based on group element $g \in \mathbb{G}$, whether $g \in \mathbb{G}_1$ or $g \in \mathbb{G}_2$, we essentially could solve the problem. Fortunately, there is such a method! Consider the following lemma.

\begin{lemma}
    Suppose $u=g^{\alpha}$. Then, $\alpha$ is even if and only if $u^n = 1$.
\end{lemma}

\textbf{Proof.} If $\alpha$ is even, then $\alpha = 2\alpha'$ and thus
\begin{equation}
    u^n = (g^{2\alpha'})^n = g^{2n\alpha'} = (g^{2n})^{\alpha'} = 1^{\alpha'} = 1
\end{equation}

Conversely, if $u^n = 1$ then $u^{\alpha n}=1$, meaning that $2n \mid \alpha n$, implying that $\alpha$ is even. Lemma is proven.

Now, we can construct our adversary $\mathcal{A}$ as follows. Suppose $\mathcal{A}$ is given $(u,v,w)$. Then,
\begin{enumerate}
    \item Based on $u$, get the parity of $\alpha$, say $p_{\alpha} \in \{\text{even}, \text{odd}\}$.
    \item Based on $v$, get the parity of $\beta$, say $p_{\beta} \in \{\text{even}, \text{odd}\}$.
    \item Based on $w$, get the parity of $\gamma$, say $p_{\gamma} \in \{\text{even}, \text{odd}\}$.
    \item Calculate $p_{\gamma}'\in \{\text{even}, \text{odd}\}$ --- parity of $\alpha\beta$.
    \item Return $\hat{b}=0$ if $p_{\gamma}' = p_{\gamma}$, and $\hat{b}=1$, otherwise.
\end{enumerate}

Suppose $\gamma$ is indeed $\alpha \times \beta$. Then, condition $p_{\gamma}'=p_{\gamma}$ will always hold. If $\gamma$ is a random element, then the probability that $p_{\gamma}'=p_{\gamma}$ is $1/2$. Therefore, the probability that $\mathcal{A}$ will guess the bit $b$ correctly is $3/4$, and the advantage is $1/4$ therefore. $\blacksquare$

\vspace{10pt}

Why is this necessary? Typically, it is impossible to prove the predicate ``for every efficient adversary $\mathcal{A}$ this probability is negligible'' and therefore we need to make assumptions, such as the Discrete Logarithm Assumption or the Computational Diffie-Hellman Assumption. In turn, proving the statement ``if $X$ is secure then $Y$ is also secure'' is manageable and does not require solving any fundamental problems. So, for example,
knowing that the probability of the adversary to break the Diffie-Hellman assumption is negligible, we can prove that the Diffie-Hellman key exchange is secure. 

\subsection{Basic Number Theory}

As mentioned earlier, the cryptography must work with integer-based formats. 
One of the earliest and most fundamental branches of mathematics is number theory, which 
deals with the properties of the integer set $\mathbb{Z}$. Although, as we will see later, 
we will primarily need the notion of \emph{prime/finite field} further, the basic concepts 
of number theory will still be used extensively nonetheless.

\subsubsection{Introduction to number theory}

We start with the most basic definition of number theory --- \emph{divisibility}.

\begin{definition}
    An integer $a$ is divisible by a non-zero integer $b$, denoted $b \mid a$ (or \emph{b is a divisor of a}), if and only if there exists an integer $k \in \mathbb{Z}$ such that $a = k \cdot b$.
\end{definition}

Let us consider some basic properties of this relation.

\begin{lemma}[Divisibility properties]
    For all $a, b, c \in \mathbb{Z}:$
    \hfill
    \begin{enumerate}
        \item $1 \mid a$ (any number is divisible by $1$)
        \item If $a \neq 0$, then $a \mid a$ (any non-zero integer divides itself).
        \item If $a \neq 0$, then $a \mid 0$ (any non-zero integer divides $0$).
        \item If $b \mid a$ and $c \mid b$, then $c \mid a$ (formally called \emph{transitivity}).
        \item $b \mid a \iff b \cdot c \mid a \cdot c$ for any $c \neq 0$.
        \item If $c \mid a$ and $c \mid b$, then $c \mid (\alpha \cdot a \pm \beta \cdot b)$, $\text{for any } \alpha, \beta \in \mathbb{Z}$
    \end{enumerate}
\end{lemma}

But what happens if a number $a$ is not divisible by the given integer $b$, meaning there is no integer $k$ that satisfies the condition $a = b \cdot k$? In such cases, a new theorem comes into play.

\begin{theorem}[Division theorem]\label{th:division}
    \begin{equation*}
        \forall a, b \in \mathbb{Z} \; \exists! q, r \in \mathbb{Z} \; \text{such that} \; a = b \cdot q + r \; \text{with} \; 0 \leq r < |b|
    \end{equation*}
\end{theorem}

To prove this theorem, all we need to prove is the existence and uniqueness of
such a decomposition. To not make the book too long, we will not prove this
theorem here, but you can find the proof in any number theory textbook.

This theorem allows us to define two new operations. Suppose $a,b,q,r$ are given
as in the \Cref{th:division}. Then,
\begin{itemize}
    \item \textbf{Floor Operation} ($\lfloor a/b \rfloor$ or $a \; \text{div} \;
b$) is defined as $q$. This operation is a standard \texttt{div} opeartion
commonly used in programming languages.
    \item \textbf{Mod Operation} ($a \; \text{mod} \; b$) is defined as $r$. This operation is a standard
\texttt{mod} operation commonly used in programming languages. 
\end{itemize}

In division operations, it is common to check for any shared factors between two
numbers. This is where the concept of the \textbf{greatest common divisor} (or
\textbf{gcd} for short) comes into play.

\begin{definition}[GCD]
    For any $a, b \in \mathbb{Z}$, the \textbf{greatest common divisor} $\gcd(a, b)$ is defined as an integer $d \in \mathbb{N}$ such that:
    \begin{enumerate}
        \item $d \mid a$ and $d \mid b$.
        \item $d$ is a maximal integer that satisfies the first condition.
    \end{enumerate}

    One might right the above definition more concisely:
    \begin{equation*}
        \gcd(a,b) = \max\{d \in \mathbb{N}: d \mid a \; \text{and} \; d \mid b\}.
    \end{equation*}
\end{definition}

\begin{definition}
    Two numbers $a$ and $b$ are \textbf{coprime} if and only if $\gcd(a, b) = 1$.
\end{definition}

As with any previous concept, let us check some basic properties of the GCD operation.

\begin{lemma} [Greatest common divisor properties]
    \hfil
    \begin{enumerate}
        \item $\gcd(a, b) = b \iff b \mid a$
        \item If $a \neq 0$, then $\gcd(a, 0) = a$
        \item If there exists $\delta \in \mathbb{Z}$ such that $\delta \mid a$ and $\delta \mid b$, then $\delta \mid \gcd(a, b)$
        \item If $c > 0$, then $\gcd(ac, bc) = c \cdot \gcd(a, b)$
        \item Suppose $d = \gcd(a, b)$. Then, $\gcd(a/d, b/d) = 1$
    \end{enumerate}
\end{lemma}

\begin{lemma}
    For any $a,b \in \mathbb{Z}$, we have $\gcd(a, b) = \gcd(b, a - b)$. 
\end{lemma}

The aforementioned lemma will be further extensively used for the Euclidean algorithm.

\begin{corollary}\label{cor:euclidean}
    As a corollary, for any $a,b \in \mathbb{Z}$ we also have $\gcd(a, b) =
    \gcd(b, a \; \text{mod} \; b)$.
\end{corollary}

All these properties are interesting and useful from the theory standpoint, but
you may wonder how to practically find $\gcd(a, b)$ (say, if you were to
implement this function in the programming language). \emph{Euclidean algorithm} is an
efficient method for computing the greatest common divisor. The main idea of 
Euclidean algorithm is to recursively apply the \Cref{cor:euclidean}. The concrete implementation 
in Python is specified below. 
\begin{lstlisting}[language=Python]
def gcd(a: int, b: int) -> int:
    return gcd(b, a % b) if b != 0 else a
\end{lstlisting}

Notice that the algorithm can be easily implemented in a single line.

While the greatest common divisor (gcd) focuses on finding the largest shared factor between two numbers, the least common multiple (lcm) deals with finding the smallest multiple that both numbers have in common. The LCM is particularly useful when we need to synchronize cycles or work with fractions.

\begin{definition}[LCM]
    For any $a, b \in \mathbb{Z}$, the \textbf{least common multiple} $\lcm(a,
    b)$ is defined as an integer $m \in \mathbb{N}$ such that:
    \begin{enumerate}
        \item $a \mid m$ and $b \mid m$
        \item $m$ is a minimal integer that satisfies the first condition 
    \end{enumerate}

    One might right the above definition more concisely:
    \begin{equation*}
        \lcm(a,b) = \min\{m \in \mathbb{N}: a \mid m \; \text{and} \; b \mid m\}.
    \end{equation*}
\end{definition}

\begin{lemma} [Least Common Multiple Properties]
    \hfil
    \begin{enumerate}
        \item We assume that $\lcm(a, 0)$ is undefined.
        \item $\lcm(a, b) = a \iff b \mid a$.
        \item If $a$ and $b$ are coprime, then $\lcm(a, b) = a \cdot b$.
        \item Any common divisor $\delta$ of $a$ and $b$ satisfies $\delta \mid \lcm(a, b)$.
        \item For any $c > 0$, we have $\lcm(a \cdot c, b \cdot b) =  c \cdot \lcm(a, b)$.
        \item Integers $\lcm(a, b)/a$ and $\lcm(a, b) / b$ are coprime.
    \end{enumerate}
\end{lemma}

\begin{theorem}
    For any $a, b \in \mathbb{N}$, we have $\gcd(a, b) \cdot \lcm(a, b) = ab$.
\end{theorem}

One interpretation of the above theorem is that no additional algorithm is required for
$\text{lcm}(a, b)$ if we already have an algorithm for $\gcd(a, b)$. Indeed, we
can simply use the formula $\text{lcm}(a, b) = ab / \gcd(a, b)$ with the
previously computed $\gcd(a, b)$.

The reasonable question is how to generalize the $\gcd$ and $\lcm$ operations to more than two arguments. 
For that reason, we provide the following algorithm:
\begin{definition}[GCD and LCM for multiple arguments]
    We define the \textbf{greatest common divisor} $\gcd(a_1, a_2, \dots, a_n)$ and the \textbf{least common multiple} $\lcm(a_1, a_2, \dots, a_n)$ for any set of integers $a_1, a_2, \dots, a_n \in \mathbb{Z}$ as follows:
    \begin{align*}
        \gcd(a_1, a_2, \dots, a_n) &= \max\{ d \in \mathbb{N}: d \mid a_1, d \mid a_2, \dots, d \mid a_n \}. \\
        \lcm(a_1, a_2, \dots, a_n) &= \min\{ m \in \mathbb{N}: a_1 \mid m, a_2 \mid m, \dots, a_n \mid m \}.
    \end{align*}
\end{definition}

\begin{theorem}[Computational Properties Of GCD and LCM For Multiple Arguments.]
    The following two statements are true:
    \begin{itemize}
        \item $\forall a, b \in \mathbb{N}: \gcd(a, b, c) = \gcd(\gcd(a, b), c) = \gcd(a, \gcd(a, b))$.
        \item $\forall a, b \in \mathbb{N}: \lcm(a, b, c) = \lcm(\lcm(a, b), c) = \lcm(a, \lcm(a, b))$.
    \end{itemize}
\end{theorem}

In conclusion, from these two theorems there is no necessity for specific
algorithms for $\gcd$ and $\lcm$ when dealing with many arguments. There are
more specialized algorithms for each when considering a specific number of
arguments, but unfortunately, such topics are beyond the scope of this book.

\subsubsection{Extended Euclidean algorithm}

In this section, we will introduce the Extended Euclidean Algorithm and an
important lemma related to the GCD. You might have reasonable question: why do
we even need an extended version? One of the primary reasons is that this 
algorithm will help in finding inverse modular elements, introduced in the 
subsequent sections.

\begin{lemma} [Bezout identity] \label{lemma:bezout_identity}
    For any two given integers $a, b \in \mathbb{N}$ with $d = \gcd(a, b)$ there exists such $u, v \in \mathbb{Z}$ that $d = au + bv$.
\end{lemma}

\begin{corollary} [From Bezout identity]
    \hfill
    \begin{enumerate}
        \item Integers $u$ and $v$ are of different signs (excluding the case when either $u=0$ or $v=0$).
        \item \textit{Generalization for multiple integers:} Suppose $d = \gcd(a_1, a_2, \dots, a_n)$, then there exist such integers $u_1, u_2, \dots, u_n \in \mathbb{Z}$ that $d = u_1 a_1 + u_2 a_2 + \cdots + u_n a_n$.
    \end{enumerate}    
\end{corollary}

The integers $u$ and $v$ are called \textbf{Bezout coefficients}. The first
corollary can be understood intuitively: if all coefficients are non-negative,
the result will be much larger than necessary. Similarly, if they are
non-positive, the result must be negative, but the GCD was defined to be
positive. The second consequence follows from the fact that we can decompose
gcd, thus sequentially derive this sequence. Also note that we can find Bezout
coefficients on each Euclidean algorithm step.

Now we introduce the \textbf{extended Euclidean algorithm.} The extended
Euclidean algorithm finds the Bezout coefficients together with the GCD
efficiently.

\begin{algorithm}[H]
    \caption{Extended Euclidean algorithm} \label{alg:extended_euclidean}
    \Input{$a, b \in \mathbb{N}$. Without loss of generality, $a \geq b$}
    \Output{$(\gcd(a, b), u, v)$}
        
    $r_{0} \gets a; \, r_{1} \gets b$ \\
    $u_{0} \gets 1; \, u_{1} \gets 0$ \\
    $v_{0} \gets 0; \, v_{1} \gets 1$ \\

    \While{$r_{i+1} \neq 0, \; i = 1, 2, \dots$}{
        $q_i \gets  r_{i-1} \; \text{div} \; r_{i}$ \\
        $u_{i+1} \gets u_{i-1} - u_{i} q_i$ \\
        $v_{i+1} \gets v_{i-1} - v_{i} q_i$ \\
        $r_{i+1} \gets  a u_{i+1} + b v_{i}$ \\
    }

    \textbf{return} $(r_i, u_i, v_i)$
\end{algorithm}

The time complexity of the Extended Euclidean algorithm is $O(\log{a} \log{b})$ bit
operations, which is very efficient. Although we already know how the
Extended Euclidean Algorithm works, this method is still not very
human-friendly. For that reason, let us consider an example of an easy way to
find the GCD.

\begin{example} [Extended Euclidean algorithm example]
    \hfill

    First, we you need to find $d = \gcd(a,b)$. Then, knowing the sequence of
    expansions, find the Bezout coefficients. Note that this can be done
    simultaneously.

    \hfill

    \begin{minipage}{0.4\textwidth}
        \raggedright
        \vspace*{\fill}
            \begin{enumerate}
                \item $125 = 93 \cdot 1 + 32$
                \item $93 = 32 \cdot 2 + 29$
                \item $32 = 29 \cdot 1 + 3$
                \item $29 = 3 \cdot 9 + 2$
                \item $3 = 2 \cdot 1 + 1$
                \item $2 = 1 \cdot 2 + 0$        
            \end{enumerate}
        \vspace*{\fill}
    \end{minipage}
    \begin{minipage}{0.7\textwidth}
        \resizebox{0.7\textwidth}{!}{
            \begin{tabular}{|c|c|c|c|c|c|c|c|}
                \hline
                
                \rowcolor{gray!30} $i$   & $0$      & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ \\
                
                \hline
                \hline

                $q_i$ & $\times$ & $1$ & $2$ & $1$ & $9$ & $1$ & $2$ \\
                
                \hline
                
                $u_i$ & $1$      & $0$ & $1$ & $-2$ & $3$ & $-29$ & $32$ \\
                \hline
                $v_i$ & $0$      & $1$ & $-1$ & $3$ & $-4$ & \textcolor{green!60!black}{\textbf{?}} & \textcolor{green!60!black}{\textbf{?}} \\
                
                \hline
            \end{tabular}
        }
    \end{minipage}

    \hfill
    
    Here, each corresponding cell is calculated with the following formula: 
    \begin{align*}
        u_{i-1} - q_i u_i &= u_{i+1} \\
        v_{i-1} - q_i v_i &= v_{i+1} 
    \end{align*}
    Knowing that, try to finish this example by filling in the missed cells
    marked by \textcolor{green!60!black}{\textbf{?}}. After finding $v_6$, be
    sure to check yourself.
\end{example}

\subsubsection{Prime numbers}

Prime numbers are fundamental in mathematics due to their role of the building
blocks of all natural numbers. Every integer greater than 1 can be uniquely
factored into primes, a concept known as the \emph{Fundamental Theorem of
Arithmetic}, which we introduce in the next section. This property makes primes
central to number theory, and they play a crucial role in various mathematical
proofs and structures.

\begin{definition}
    Number $n \in \mathbb{N}$ is \textbf{prime} iff its only two divisors are $1$
    and $n$. 
\end{definition}

\begin{definition}
    Number $n \in \mathbb{N}$ is \textbf{composite} iff there exists an integer
    $a \in \mathbb{N}$, which is not $1$ or $n$, for which $a \mid n$. In other words,
    it is not prime.
\end{definition}

\begin{remark}
    One might ask: what to do with the number $1$? We consider it to
    be neither prime nor composite.
\end{remark}

\begin{lemma}
    For all $n \in \mathbb{N}$, we have $\gcd(n, n+1) = 1$
\end{lemma}

\begin{theorem} [Euclidean theorem]
    If $P = \{p_1, p_2, p_3, \dots p_k\} \subset \mathbb{N}$ is a finite set,
    consisting of prime numbers, then there exists a prime number $p$ such that
    $p \notin P$.
\end{theorem}

\begin{corollary}
    The set of prime numbers has an infinite cardinality.
\end{corollary}

\begin{lemma}
    For all $n \in \mathbb{N}$, where $n$ is composite, if there exists a 
    minimal divisor $d>1$ of $n$, then $d$ is a prime number.
\end{lemma}

Let's say we have a large number and we need to find out if it is prime, how do we do it?
In other words, are there any methods for checking a number for prime?
Yes, there are, starting with logical reasoning, you can check numbers with brute force, although
this method is not practically applicable. There are probabilistic prime tests that will fail
with some error. In 2003, an effective deterministic test of simplicity was found, which moved
the problem to the class $P$.

It is worth to be mentioned, there are also different forms of primes that find their application in some fields. 
For example, Mersenne primes, factorial primes, Euclidean primes, Fibonacci primes, and many other types of primes.
We will consider one of the most famous types of primes --- Mersenne primes.

\begin{definition} [Mersenne primes]
    The prime number of form $2^p - 1$ is called \textbf{Mersenne prime}, where $p$ is a
    prime number.
\end{definition}

Mersenne primes, are important in both number theory and cryptography.
They have unique mathematical properties that make them useful for testing primality and generating large prime numbers.
Mersenne primes are also crucial in the construction of efficient algorithms for error correction in coding theory and for generating random numbers in cryptographic applications, etc. 
Beside, next theorem importan says that we can know the form of a prime numbers.

\begin{theorem} [Dirichlet's theorem]
    For any $a, b \in \mathbb{N}$ if $\gcd(a, b) = 1$, then infinite primes number form of $am + b$ exists, where $m \in \mathbb{N}$.
\end{theorem}

In other words, every infinite arithmetic progression whose first term and difference are positive integers contains an infinite number of primes.

\subsubsection{Fundamental Theorem of Arithmetic}
The Fundamental Theorem of Arithmetic states that every integer greater than 1 can be uniquely factored into primes, which is crucial for understanding the structure of numbers. 
It plays a key role in areas like number theory, cryptography, and simplifying calculations involving divisibility. 
But before formal description of the theorem, for better understanding it is good to know the following Lemma \ref{euclidean_lemma}.

\begin{lemma}[Euclidean lemma] \label{euclidean_lemma}
    If $p$ is a prime and $p \mid ab$, then $p \mid a$ or $p \mid b$.
\end{lemma}

\textbf{Proof.} 
$\blacktriangleright$
Let $p \mid ab$, but $ p \nmid a$, then $\gcd(a, p) = 1$ because there are no common divisors.
In which case, by Bezout identity \Cref{lemma:bezout_identity}, there exist such $u, v \in \mathbb{Z}$ that $au + pv = 1$.
Let's multiply the left and right sides by $b$: $abu + pbv = b$, but $p \mid ab$ and $p \mid pb$, therefore their sum is also divisible by $p \mid abu + pbv$. 
$\blacktriangleleft$

Now, we are ready to introduce the central Number Theory theorem --- Fundamental
Theorem of Arithmetic.

\begin{theorem}[Fundamental theorem of arithmetic]\label{th:fundamental_arithmetic}
    Any integer $n>1$ can be decomposed in the unique way into a product of prime numbers:
    \begin{equation*}
        n = p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_t^{\alpha_t} = \prod_{j=1}^t p_j^{\alpha_j},
    \end{equation*}
    where $p_1,\dots,p_t$ are prime numbers and $\alpha_1,\dots,\alpha_t \in \mathbb{N}$.
\end{theorem}

\textbf{Proof.} 
$\blacktriangleright$  
The theorem state equation then need to proof equation existence and uniqueness. Since the existence property is 
easy to prove, let us make the small exception and show it. For other proves (in particular, for the uniqueness case, see literature)

\textcolor{green!60!black}{\textbf{Existence}}. Suppose the theorem statement is false and there exist $n$ that do not have such a representation.
Let $n_0$ be the smallest of them.
If $n_0$ is prime, it can be represented as $p_1=n_0$, $\alpha_1=1$, which satisfies the representation. Therefore, $n_0$ must be composite, which means $\exists a, b \in \mathbb{N}, 1 < a, b < n_0$ such that $n = ab$.
Since $n_0$ is the smallest non-decomposable number and $a, b < n_0$, then $a$ and $b$ can be represented as 
\begin{align*}
    a &= p_{1}^{\alpha_{1}} \dots p_{t}^{\alpha_{t}} \\
    b &= q_{1}^{\beta_{1}} \dots q_{k}^{\beta_{k}}.
\end{align*}
Therefore, $n_0 = ab=p_{1}^{\alpha_{1}} \dots p_{t}^{\alpha_{t}} q_{1}^{\beta_{1}} \dots q_{k}^{\beta_{k}}$. Thus, the contradiction. $\blacktriangleleft$  

\begin{corollary}
    Suppose $n$ is decomposed as in \Cref{th:fundamental_arithmetic}. Then,

    \begin{enumerate}
        \item If $d \mid n$, then $d = p_{1}^{\beta_1}p_{2}^{\beta_2} \dots p_{t}^{\beta_t}$, where $0 \leq \beta_i \leq \alpha_i$.
        \item Suppose $a = p_{1}^{\alpha_1} \dots p_{t}^{\alpha_t}$ and $b = p_{1}^{\beta_1} \dots p_{t}^{\beta_t}$. Then, the GCD can be evaluated as $\gcd(a, b) = \prod_{i=0}^{t}p^{\min\{\alpha_i, \beta_i\}}$.
        \item Suppose $a = p_{1}^{\alpha_1} \dots p_{t}^{\alpha_t}$ and $b = p_{1}^{\beta_1} \dots p_{t}^{\beta_t}$. Then, the LCM can be evaluated as $\lcm(a, b) = \prod_{i=0}^{t}p^{\max\{\alpha_i, \beta_i\}}$.
        \item If $b \mid a$ and $c \mid a$ and $\gcd(b, c) = 1$, then $bc \mid a$.
    \end{enumerate}
\end{corollary}

The implications and applications of the Fundamental Theorem of Arithmetic are very large and important, and a number of “obvious” ones are listed above.
However, you should also be aware that the problem of factorization, i.e., knowing the decomposition of a number into prime factors, is in a NP class (complexity) and is the basis of some cryptosystems, although it is gradually being abandoned, including due to the potential of quantum computers.

\subsubsection{Modular arithmetic}

Now we are ready for practical applications of number theory, starting with modulo congruence.
In this section, we will review the idea of congruence, learn how to use it, and explore
its key properties. Understanding these properties will help simplify calculations and solve 
problems more efficiently in fields such as cryptography, algorithms, and number theory.

\begin{definition}
    Two integers $a, b \in \mathbb{Z}$ are said to be \textbf{congruent} modulo $n \in \mathbb{N}$ (congruence modulo $n$ is denoted as $a \equiv b \pmod{n}$), if one of the following conditions is met:
    \begin{enumerate}
        \item There exists such $t \in \mathbb{Z}$ that $a = b + nt$
        \item $a \; \texttt{mod} \; n = b \; \texttt{mod} \; n$
        \item $n \mid (a - b)$
    \end{enumerate}
\end{definition}

It is fairly easy to see that all conditions are equivalent to each other. Next, as always, it is necessary to formally describe the properties, although some of them may seem intuitive, they need to be formally defined.

\begin{lemma}[Reflexivity, Symmetry, and Transitivity] 
    \hfill
    \begin{enumerate}
        \item $a \equiv a \pmod{n}$
        \item If $a \equiv b \pmod{n}$, then $b \equiv a \pmod{n}$
        \item If $a \equiv b \pmod{n}$ and $b \equiv c \pmod{n}$, then $a \equiv c \pmod{n}$
    \end{enumerate}
\end{lemma}

The lemma states three basic properties of congruence modulo $n$: reflexivity, symmetry, and transitivity. 
These properties confirm that congruence modulo $n$ is an equivalence relation (for general equivalence relation definition, see \Cref{section:relations}).

\begin{lemma}
    Suppose we have $a \equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then we have 
        \begin{enumerate}
            \item $a \pm c \equiv b \pm d \pmod{n}$
            \item $ac \equiv bd \pmod{n}$
        \end{enumerate}
\end{lemma}

In turn, this lemma states that we can perform addition, subtraction, and multiplication on the congruent numbers modulo $n$ similarly to the usual arithmetic.

\begin{lemma}
    If $ca \equiv cb \pmod{n}$ and $\gcd(c, n) = 1$, then $ a \equiv b \pmod{n}$.
\end{lemma}

This means that we can cancel out the same left and right parts respectively, but with a certain requirement. You may ask why this is necessary, the answer is in the following example.

\begin{example}
    Let us try to simplify the following equation: $6 \equiv 2 \pmod{4}$. Suppose we divide both sides by $2$, then we have the false statement $3 \equiv 1 \pmod{4}$. That being said, the requirement $\gcd(c, n) = 1$ is mandatory. 
\end{example}

\begin{remark}
    In particular, the example above shows why the division operation is fundamentally different from the regular real/rational numbers. We will see that, in fact, the arithmetic modulo $n$ is not always what mathematicians call a \textbf{field}. You will see more details in \Cref{section:field_extensions}.
\end{remark}

\begin{lemma}
    Modulo congruence can be scaled in both directions:
    
    \begin{enumerate}
        \item If $k \neq 0, a \equiv b \pmod{n}$, then $ak \equiv bk \pmod{nk}$
        \item If $d = \gcd(a, b, n) \text{ and } a = a_1d, b =b_1d, n = n_1d, a \equiv b \, (\text{mod } n)$, then $a_1 = b_1 \, (\text{mod } n_1)$
    \end{enumerate}
\end{lemma}

\begin{lemma}
    If $d \mid n$ and $a \equiv b \, (\text{mod } n)$, then $a \equiv b \, (\text{mod } d)$.
\end{lemma}

This property is very convenient when it comes to large calculations, if you know its decomposition.
It allows you to significantly reduce them, and then restore the result by a large modulus.

\begin{lemma}
    Suppose $a \equiv b \pmod{n_1}$, $a \equiv b \pmod{n_2}$, \ldots, $a \equiv b \pmod{n_k}$. Then, the following statement is true: 
    \begin{equation*}
        a \equiv b \pmod{\lcm(n_1, n_2, \dots, n_k)}.
    \end{equation*}
\end{lemma}

\begin{lemma}
    If $a \equiv b \, (\text{mod } n)$, then $\gcd(a, n) = \gcd(b, n)$
\end{lemma}

\begin{definition}
    The congruence class or residues of $k$ modulo $n$ is defined as a set $k + n\mathbb{Z} = \{ k + nt \mid t \in \mathbb{Z}\}$    
\end{definition}

\begin{definition}
    The \textbf{complete residue system modulo} (or residue ring) $n$ is a set of integers, where
    every integer is congruent to a unique member of the set modulo $n$, usually denoted
    as $\mathbb{Z}_n = \{0, 1, 2, \dots, n-1\}$.
\end{definition}

\begin{remark}
    Sometimes, one might also encounter the notation $\mathbb{Z}/n\mathbb{Z}$, which is more frequently used in Abstract Algebra.
\end{remark}

The aforementioned lemmas and definitions describe the properties of addition, subtraction, and multiplication. But what about division? To define the division (if such operation is valid at all), we need to consider the so-called \emph{modular multiplicative inverse}, which is usually denoted as $a^{-1} \, (\text{mod } n)$, similarly to real/rational numbers.

\begin{definition}
    A modular multiplicative inverse of an integer $a \in \mathbb{Z}$ modulo $n \in \mathbb{N}$ is such an integer $a^{-1}$ that satisfies $a \cdot a^{-1} \equiv a^{-1}a \equiv 1 \pmod{n}$.
\end{definition}

\begin{remark}
    (\textbf{Caution}): not all numbers have an inverse number!
\end{remark}

\begin{remark}
    The inverse (if exists) behaves similarly to the usual inverse over rations/reals. For example, $(a^{2})^{-1} = (a^{-1})^{2}$, which means, we can first find the inverse, then the squared value, and vice versa.
\end{remark}

The question then is when does the number have the inverse? Consider the following theorem.

\begin{theorem}\label{th:inverse_existence}
    Modular inverse $a^{-1} \pmod{n}$ exists if and only if $\gcd(a, n) = 1$.
\end{theorem}

Based on Extended Euclidean \Cref{alg:extended_euclidean} and \Cref{th:inverse_existence}, we build the algorithm that can verify an existence and find the inverse value.

\begin{algorithm}
    \caption{Modular multiplicative inverse algorithm} \label{alg:modular_inverse}
    \Input{$a, n$}
    \Output{$a^{-1}$}
        
    $(d, u, v) \gets \text{ExtendedEuclideanAlgorithm}(a, n)$ \Comment{See \Cref{alg:extended_euclidean}}

    \If{$d \neq 1$}{
        \textbf{return} inverse does not exist.
    } 

    \textbf{return} $u$
\end{algorithm}

\begin{remark}
    Note that the complexity of this algorithm is the same as for \Cref{alg:extended_euclidean}, which is $O(\log a \log n)$ bit operations.
\end{remark}

\begin{definition}
    The \textbf{multiplicative group of integers} modulo $n$, denoted as $\mathbb{Z}_n^{\times}$, is a set of natural numbers that are coprime to $n$ and less than $n$. In other words, $\mathbb{Z}_n^{\times} = \{a \in \mathbb{N}: \gcd(a, n) = 1\}$.
\end{definition}

The $\mathbb{Z}_{n}^{\times}$ is a fundamental object in number theory and 
plays a crucial role in cryptography, forming the basis almost for every cryptographic primitive.

\begin{definition}
    \textbf{Euler's Totient Functiom} $\varphi(n)$ is the cardinality of the multiplication 
    group of integers $\mathbb{Z}_n^{\times}$. In other words, $\varphi(n) = |\mathbb{Z}_n^{\times}|$.
\end{definition}

\begin{remark}
    The alternative Euler's totient function intuition is following: $\varphi(n)$ counts all coprimes with $n$ in range $[1, n]$. 
\end{remark}

\begin{lemma} [Euler's totient function properties]
    \hfill
    \begin{enumerate}
        \item $\varphi(1) = 1$.
        \item $\varphi(p) = p - 1$, $p$ where is prime.
        \item $\varphi(pq) = \varphi(p) \cdot \varphi(q)$, where $p, q$ are primes.
        \item $\varphi(p^{\alpha}) = p^{\alpha} - p^{\alpha - 1}$, where  $p$ is prime.        
    \end{enumerate}    
\end{lemma}

\begin{corollary}
    For any number $n = p_{1}^{\alpha_1}p_{2}^{\alpha_2} \dots p_{t}^{\alpha_t}$ general formula for Euler's totient function is: 
    \begin{equation*}
        \varphi(n) = \prod_{i = 1}^{t} \left( p_{i}^{\alpha_i} - p_{i}^{\alpha_i - 1} \right) = n \prod_{i = 1}^{t} \left( 1 - \frac{1}{p_i} \right).
    \end{equation*}
\end{corollary}

\begin{example}
    \hfill

    \begin{itemize}
        \item $\varphi(107) = 106$, because $107$ is prime.
        \item $\varphi(123) = \varphi(3 \cdot 41) = \varphi(3)\varphi(41) = 2 \cdot 40 = 80$
        \item $\varphi(729) = \varphi(3^6) = 3^6 - 3^5 = 486$
    \end{itemize}
\end{example}

\subsubsection{Schwartz-Zippel Lemma}

\begin{lemma}\label{lemma:sz}
Let $\mathbb{F}$ be a field. Let $f(x_1, x_2, ..., x_n)$ be a polynomial of total degree $d$. Suppose that $f$ is not the zero polynomial. Let $S$ be
a finite subset of $\mathbb{F}$. Let $r_1, r_2, ... r_n$ be chosen at random uniformly and independently from $S$. Then the probability that 
$f(r_1, r_2, ..., r_n) = 0$ is $\le \frac{d}{|S|}$.
\end{lemma}

\begin{example}
Let $F = \F_3$, $f(x) = x^2 - 5x + 6$, $S = F$, $r \xleftarrow{R} \mathbb{F}_3$.

Schwartz-Zippel lemma says that the probability that $f(r) = 0$ is $\le \frac{2}{3}$.
\end{example}

Given two polynomials $P, Q$ with  degree $d$ in a field $\F_p$, for $r \xleftarrow{R} \mathbb{F}_3$: $\Pr[P(r) == Q(r)] \le \frac{d}{p}$.
For large fields, where  $\frac{d}{p}$ is negligible, this property allows to succinctly check the equality of polynomials.
Let $H(x) := P(x) - Q(x)$. Than for each $P(x) = Q(x) \rightarrow H(x) = 0$. Applying Schwartz-Zippel lemma, 
the probability of $H(x) = 0$ for $x \xleftarrow{R} \mathbb{F} $ is $\le \frac{d}{|S|}$.

\subsection{Exercises}

\textbf{Exercise 1.} Suppose that for the given cipher with a security parameter $\lambda$, the adversary $\mathcal{A}$ can deduce the least significant bit of the plaintext from the ciphertext. Recall that the advantage 
of a bit-guessing game is defined as $\text{SS}\mathsf{Adv}[\mathcal{A}] = \left|\Pr[b=\hat{b}] - \frac{1}{2}\right|$, where $b$ is the randomly chosen bit of a challenger, while 
$\hat{b}$ is the adversary's guess. What is the maximal advantage of $\mathcal{A}$ in this case?

\textbf{Hint:} The adversary can choose which messages to send to challenger to further distinguish the plaintexts.

\begin{enumerate}[a)]
    \item $1$
    \item $\frac{1}{2}$
    \item $\frac{1}{4}$
    \item $0$
    \item Negligible value ($\text{negl}(\lambda)$).
\end{enumerate}

\textbf{Exercise 2.} Consider the cipher $\mathcal{E} = (E,D)$ with encryption function $E: \mathcal{K} \times \mathcal{M} \to \mathcal{C}$ over the message space $\mathcal{M}$, ciphertext space $\mathcal{C}$, and key space $\mathcal{K}$. We want to define the security
that, based on the cipher, the adversary $\mathcal{A}$ cannot restore the message (\textit{security against message recovery}). For that reason, we define the following game:
\begin{enumerate}
    \item Challenger chooses random $m \xleftarrow{R} \mathcal{M}, k \xleftarrow{R} \mathcal{K}$.
    \item Challenger computes the ciphertext $c \gets E(k,m)$ and sends to $\mathcal{A}$.
    \item Adversary outputs $\hat{m}$, and wins if $\hat{m} = m$.
\end{enumerate}

We say that the cipher $\mathcal{E}$ is secure against message recovery if the \textbf{message recovery advantage}, denoted as $\text{MR}\textsf{adv}[\mathcal{A}, \mathcal{E}]$ is negligible. Which of the following statements is a valid interpretation of the message recovery advantage?
\begin{enumerate}[a)]
    \item $\text{MR}\textsf{adv}[\mathcal{A},\mathcal{E}] := \left|\text{Pr}[m=\hat{m}] - \frac{1}{2}\right|$
    \item $\text{MR}\textsf{adv}[\mathcal{A},\mathcal{E}] := \left|\text{Pr}[m=\hat{m}] - 1\right|$.
    \item $\text{MR}\textsf{adv}[\mathcal{A},\mathcal{E}] := \text{Pr}[m=\hat{m}]$
    \item $\text{MR}\textsf{adv}[\mathcal{A},\mathcal{E}] := \left|\text{Pr}[m=\hat{m}] - \frac{1}{|\mathcal{M}|}\right|$
\end{enumerate}

\textbf{Exercise 3.} Suppose that $f$ and $g$ are negligible functions. Which of the following functions is not neccessarily negligible?
\begin{enumerate}[a)]
    \item $f + g$
    \item $f \times g$
    \item $f - g$
    \item $f/g$
    \item $h(\lambda) := \begin{cases}
        1/f(\lambda) & \text{if } 0 < \lambda < 100000 \\
        g(\lambda) & \text{if } \lambda \geq 100000
    \end{cases}$
\end{enumerate}

\textbf{Exercise 4.} Suppose that $f \in \mathbb{F}_p[x]$ is a $d$-degree polynomial with $d$ \textbf{distinct} roots in $\mathbb{F}_p$. What is the probability that, when evaluating $f$ at $n$ random points, the polynomial will be zero at all of them?

\begin{enumerate}[a)]
    \item Exactly $(d/p)^n$.
    \item Strictly less that $(d/p)^n$.
    \item Exactly $nd/p$.
    \item Exactly $d/np$.
\end{enumerate}

\textbf{Exercise 5-6.} To demonstrate the idea of Reed-Solomon codes, consider the toy construction. Suppose that our message is a tuple of two elements $a,b \in \mathbb{F}_{13}$. Consider function $f: \mathbb{F}_{13} \to \mathbb{F}_{13}$, defined as $f(x) = ax+b$, and define the encoding of the message $(a,b)$ as $(a,b) \mapsto (f(0),f(1),f(2),f(3))$. 

\textbf{Question 5.} Suppose that you received the encoded message $(3,5,6,9)$. Which number from the encoded message is corrupted?
\begin{enumerate}[a)]
    \item First element ($3$).
    \item Second element ($5$).
    \item Third element ($6$).
    \item Fourth element ($9$).
    \item The message is not corrupted.
\end{enumerate}

\textbf{Question 6.} Consider the previous question. Suppose that the original message was $(a,b)$. Find the value of $a \times b$ (in $\mathbb{F}_{13}$).
\begin{enumerate}[a)]
    \item $4$
    \item $6$
    \item $12$
    \item $2$
    \item $1$
\end{enumerate}

\end{document}